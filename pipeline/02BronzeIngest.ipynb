{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a4528a9b-f897-4daf-bb4e-8cf01d402df4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Purpose: Bronze Ingest\n",
    "\n",
    "This step ingests approved study workbooks into the Bronze layer as raw, traceable Delta tables.\n",
    "\n",
    "Only workbooks from cornell_catalog.cornell_schema.gemsGateResults with the latest runId, duaExists = true, and checklistOk = true are processed. For each approved workbook, selected sheets are read exactly as provided and written to Bronze without modification.\n",
    "\n",
    "Standard metadata columns are attached to every table (studyId, contractName, sequence, workbookFile, workbookPath, sourceSheet, gateRunId, ingestRunId, ingestTsUtc) to ensure consistency, lineage, and reproducibility.\n",
    "\n",
    "No cleaning, deduplication, or filtering is performed at this stage. Bronze data is raw but organized. All validation and example-row filtering (via comparison to DataEntryTemplate.xlsx) is intentionally deferred to the Silver layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f3b077ac-0541-4404-89b6-f16c47743362",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Cell 1 — Imports + config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38694e75-7c42-4505-8ede-4d244a61004a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# Purpose:\n",
    "#   - Set paths and table names\n",
    "#   - Keep all naming camelCase (per your preference)\n",
    "# Notes:\n",
    "#   - Bronze tables are append-only\n",
    "#   - We store raw sheets with minimal typing changes\n",
    "# ---------------------------------------------\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "dataVolumePath = \"/Volumes/cornell_catalog/cornell_schema/blob_gems_data\"\n",
    "\n",
    "# Source gate results table (already created by DiscoverAndGate)\n",
    "gateResultsTable = \"cornell_catalog.cornell_schema.gemsGateResults\"\n",
    "\n",
    "# Bronze table name prefix (one table per sheet, shared across all studies)\n",
    "bronzeTablePrefix = \"cornell_catalog.cornell_schema.bronze\"\n",
    "\n",
    "# Ops log table for ingest status (optional but strongly recommended)\n",
    "bronzeIngestLogTable = \"cornell_catalog.cornell_schema.gemsBronzeIngestLog\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7753abe7-c46b-46db-a3e9-cb82cbde88e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Cell 2 — Get latest approved workbooks from GateResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "025158be-70fe-4929-a108-68be3ca54d0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>studyId</th><th>contractName</th><th>sequence</th><th>workbookFile</th><th>workbookPath</th><th>duaFile</th><th>duaPath</th><th>duaExists</th><th>checklistOk</th><th>checklistError</th><th>gateRunId</th></tr></thead><tbody><tr><td>012</td><td>PuchunNiu</td><td>1</td><td>012_PuchunNiu_1.xlsx</td><td>/Volumes/cornell_catalog/cornell_schema/blob_gems_data/012_PuchunNiu_1.xlsx</td><td>PuchunNiu.pdf</td><td>/Volumes/cornell_catalog/cornell_schema/blob_gems_dua/PuchunNiu.pdf</td><td>true</td><td>true</td><td>null</td><td>20260212T154946Z</td></tr><tr><td>013</td><td>PuchunNiu</td><td>2</td><td>013_PuchunNiu_2.xlsx</td><td>/Volumes/cornell_catalog/cornell_schema/blob_gems_data/013_PuchunNiu_2.xlsx</td><td>PuchunNiu.pdf</td><td>/Volumes/cornell_catalog/cornell_schema/blob_gems_dua/PuchunNiu.pdf</td><td>true</td><td>true</td><td>null</td><td>20260212T154946Z</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "012",
         "PuchunNiu",
         "1",
         "012_PuchunNiu_1.xlsx",
         "/Volumes/cornell_catalog/cornell_schema/blob_gems_data/012_PuchunNiu_1.xlsx",
         "PuchunNiu.pdf",
         "/Volumes/cornell_catalog/cornell_schema/blob_gems_dua/PuchunNiu.pdf",
         true,
         true,
         null,
         "20260212T154946Z"
        ],
        [
         "013",
         "PuchunNiu",
         "2",
         "013_PuchunNiu_2.xlsx",
         "/Volumes/cornell_catalog/cornell_schema/blob_gems_data/013_PuchunNiu_2.xlsx",
         "PuchunNiu.pdf",
         "/Volumes/cornell_catalog/cornell_schema/blob_gems_dua/PuchunNiu.pdf",
         true,
         true,
         null,
         "20260212T154946Z"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "studyId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "contractName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "sequence",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "workbookFile",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "workbookPath",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "duaFile",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "duaPath",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "duaExists",
         "type": "\"boolean\""
        },
        {
         "metadata": "{}",
         "name": "checklistOk",
         "type": "\"boolean\""
        },
        {
         "metadata": "{}",
         "name": "checklistError",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "gateRunId",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latestGateRunId: 20260212T154946Z\napproved workbooks: 2\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# Purpose:\n",
    "#   - Find latest gateRunId\n",
    "#   - Select only rows where:\n",
    "#       duaExists = true AND checklistOk = true\n",
    "# Notes:\n",
    "#   - This is how we ensure Bronze only ingests \"approved\" inputs\n",
    "# ---------------------------------------------\n",
    "\n",
    "latestGateRunId = (\n",
    "    spark.sql(f\"SELECT max(runId) AS runId FROM {gateResultsTable}\")\n",
    "         .collect()[0][\"runId\"]\n",
    ")\n",
    "\n",
    "approvedDf = spark.sql(f\"\"\"\n",
    "    SELECT\n",
    "      studyId,\n",
    "      contractName,\n",
    "      sequence,\n",
    "      workbookFile,\n",
    "      workbookPath,\n",
    "      duaFile,\n",
    "      duaPath,\n",
    "      duaExists,\n",
    "      checklistOk,\n",
    "      checklistError,\n",
    "      runId AS gateRunId\n",
    "    FROM {gateResultsTable}\n",
    "    WHERE runId = '{latestGateRunId}'\n",
    "      AND duaExists = true\n",
    "      AND checklistOk = true\n",
    "\"\"\")\n",
    "\n",
    "display(approvedDf)\n",
    "print(\"latestGateRunId:\", latestGateRunId)\n",
    "print(\"approved workbooks:\", approvedDf.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e470ba8f-da27-4da3-86e2-99900ea33ec8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Cell 3 — Define which sheets to ingest + helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a8d381d-3168-49e8-9f73-686b794a3471",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# Purpose:\n",
    "#   - Define which sheets we ingest in this MVP\n",
    "#   - Provide a robust function that:\n",
    "#       * reads a sheet via pandas/openpyxl\n",
    "#       * converts to Spark\n",
    "#       * adds metadata columns\n",
    "#       * writes to the correct Bronze table\n",
    "# Notes:\n",
    "#   - We ingest only a few sheets first to reduce risk and debugging time.\n",
    "#   - Expanding to \"all sheets\" is easy: just add names to sheetNamesToIngest.\n",
    "# ---------------------------------------------\n",
    "\n",
    "from datetime import datetime, timezone  # ensure available (used for unit capture timestamps)\n",
    "\n",
    "# MVP sheet list (start small; we can expand safely)\n",
    "sheetNamesToIngest = [\n",
    "    \"Contributor\",\n",
    "    \"AnimalCharacteristics\",\n",
    "    \"ExperimentalDesign\",\n",
    "    \"FeedComponents\",\n",
    "    \"DietNutrientComposition\",\n",
    "    \"IntakePerDay\",\n",
    "    \"IntakeIntraday\",\n",
    "    \"Milk\",\n",
    "    \"BodyWeight\",\n",
    "    \"Digestibility\",\n",
    "    # add more later (GreenFeedSettings, SF6, etc.)\n",
    "]\n",
    "\n",
    "def bronzeTableNameForSheet(sheetName: str) -> str:\n",
    "    # Example: bronze + \"AnimalCharacteristics\" -> cornell_catalog.cornell_schema.bronzeAnimalCharacteristics\n",
    "    return f\"{bronzeTablePrefix}{sheetName}\"\n",
    "\n",
    "# NEW: ops table to store units (one row per column)\n",
    "# Use your existing catalog/schema variables if you have them; otherwise set the full name string.\n",
    "try:\n",
    "    opsSheetUnitsTable = f\"{cornellCatalog}.{cornellSchema}.opsSheetUnits\"\n",
    "except NameError:\n",
    "    opsSheetUnitsTable = \"cornell_catalog.cornell_schema.opsSheetUnits\"\n",
    "\n",
    "\n",
    "def ingestOneSheetToBronze(\n",
    "    workbookPath: str,\n",
    "    workbookFile: str,\n",
    "    studyId: str,\n",
    "    contractName: str,\n",
    "    sequence: str,\n",
    "    gateRunId: str,\n",
    "    ingestRunId: str,\n",
    "    sheetName: str\n",
    "):\n",
    "    # ---------------------------------------------------------\n",
    "    # NEW: Capture Unit row (Excel row 4) into opsSheetUnitsTable\n",
    "    # Template structure assumed consistent across all sheets:\n",
    "    #   Row 1: column names\n",
    "    #   Row 2: definitions\n",
    "    #   Row 3: prioritization\n",
    "    #   Row 4: unit\n",
    "    #   Row 5+: data\n",
    "    #\n",
    "    # With header=0 and nrows=4:\n",
    "    #   head4.iloc[0] => definitions (Excel row 2)\n",
    "    #   head4.iloc[1] => prioritization (Excel row 3)\n",
    "    #   head4.iloc[2] => unit (Excel row 4)   <-- we capture this\n",
    "    #   head4.iloc[3] => first data row (Excel row 5) (ignored here)\n",
    "    # ---------------------------------------------------------\n",
    "    head4 = pd.read_excel(\n",
    "        workbookPath,\n",
    "        sheet_name=sheetName,\n",
    "        engine=\"openpyxl\",\n",
    "        header=0,\n",
    "        nrows=4,\n",
    "        dtype=str,\n",
    "        keep_default_na=False\n",
    "    )\n",
    "    head4.columns = [str(c).strip() for c in head4.columns]\n",
    "\n",
    "    unit_dict = head4.iloc[2].to_dict()\n",
    "\n",
    "    unit_rows = [{\n",
    "        \"studyId\": studyId,\n",
    "        \"contractName\": contractName,\n",
    "        \"sequence\": sequence,\n",
    "        \"workbookFile\": workbookFile,\n",
    "        \"workbookPath\": workbookPath,\n",
    "        \"sourceSheet\": sheetName,\n",
    "        \"columnName\": str(col),\n",
    "        \"unit\": None if pd.isna(u) else str(u),\n",
    "        \"gateRunId\": gateRunId,\n",
    "        \"ingestRunId\": ingestRunId,\n",
    "        \"ingestTsUtc\": datetime.now(timezone.utc).isoformat()\n",
    "    } for col, u in unit_dict.items()]\n",
    "\n",
    "    unitsSdf = spark.createDataFrame(pd.DataFrame(unit_rows))\n",
    "\n",
    "    (\n",
    "        unitsSdf.write\n",
    "            .format(\"delta\")\n",
    "            .mode(\"overwrite\")\n",
    "            .option(\n",
    "                \"replaceWhere\",\n",
    "                f\"studyId = '{studyId}' AND sequence = '{sequence}' AND sourceSheet = '{sheetName}'\"\n",
    "            )\n",
    "            .option(\"mergeSchema\", \"true\")\n",
    "            .saveAsTable(opsSheetUnitsTable)\n",
    "    )\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # Existing: Read data rows only (skip template rows 2–4)\n",
    "    # ---------------------------------------------------------\n",
    "    pdf = pd.read_excel(\n",
    "        workbookPath,\n",
    "        sheet_name=sheetName,\n",
    "        engine=\"openpyxl\",\n",
    "        skiprows=[1,2,3],\n",
    "        dtype=str,\n",
    "        keep_default_na=False\n",
    "    )\n",
    "\n",
    "    pdf.columns = [str(c).strip() for c in pdf.columns]\n",
    "    \n",
    "    # Convert to Spark\n",
    "    sdf = spark.createDataFrame(pdf)\n",
    "\n",
    "    # Add metadata for traceability and avoiding conflicts across studies\n",
    "    sdf = (\n",
    "        sdf\n",
    "        .withColumn(\"studyId\", F.lit(studyId))\n",
    "        .withColumn(\"contractName\", F.lit(contractName))\n",
    "        .withColumn(\"sequence\", F.lit(sequence))\n",
    "        .withColumn(\"workbookFile\", F.lit(workbookFile))\n",
    "        .withColumn(\"workbookPath\", F.lit(workbookPath))\n",
    "        .withColumn(\"sourceSheet\", F.lit(sheetName))\n",
    "        .withColumn(\"gateRunId\", F.lit(gateRunId))\n",
    "        .withColumn(\"ingestRunId\", F.lit(ingestRunId))\n",
    "        .withColumn(\"ingestTsUtc\", F.current_timestamp())\n",
    "    )\n",
    "\n",
    "    # Write to Bronze (overwrite this study+sheet on rerun)\n",
    "    targetTable = bronzeTableNameForSheet(sheetName)\n",
    "\n",
    "    (\n",
    "        sdf.write\n",
    "            .format(\"delta\")\n",
    "            .mode(\"overwrite\")\n",
    "            .option(\n",
    "                \"replaceWhere\",\n",
    "                f\"studyId = '{studyId}' AND sequence = '{sequence}' AND sourceSheet = '{sheetName}'\"\n",
    "            )\n",
    "            .option(\"mergeSchema\", \"true\")\n",
    "            .saveAsTable(targetTable)\n",
    "    )\n",
    "\n",
    "    totalRows = sdf.count()\n",
    "    reportedRows = totalRows  # since we skipped template rows already\n",
    "\n",
    "    return targetTable, reportedRows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae55fc1c-bd5a-46b2-9306-6d6a5ac30487",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Cell 4 — Ingest loop + log successes/failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3be04ccf-9fb0-4a60-8bef-68b3d2ad0656",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# Purpose:\n",
    "#   - For each approved workbook:\n",
    "#       ingest each selected sheet into its Bronze table\n",
    "#   - Write an ops log row per (workbook, sheet) so we can debug later\n",
    "# Notes:\n",
    "#   - If a sheet is missing, we log an error but continue with other sheets\n",
    "# ---------------------------------------------\n",
    "\n",
    "ingestRunId = datetime.now(timezone.utc).strftime(\"%Y%m%dT%H%M%SZ\")\n",
    "\n",
    "approvedRows = approvedDf.collect()\n",
    "\n",
    "logRows = []\n",
    "\n",
    "for r in approvedRows:\n",
    "    studyId = r[\"studyId\"]\n",
    "    contractName = r[\"contractName\"]\n",
    "    sequence = r[\"sequence\"]\n",
    "    workbookFile = r[\"workbookFile\"]\n",
    "    workbookPath = r[\"workbookPath\"]\n",
    "    gateRunId = r[\"gateRunId\"]\n",
    "\n",
    "    for sheetName in sheetNamesToIngest:\n",
    "        try:\n",
    "            targetTable, rowCount = ingestOneSheetToBronze(\n",
    "                workbookPath=workbookPath,\n",
    "                workbookFile=workbookFile,\n",
    "                studyId=studyId,\n",
    "                contractName=contractName,\n",
    "                sequence=sequence,\n",
    "                gateRunId=gateRunId,\n",
    "                ingestRunId=ingestRunId,\n",
    "                sheetName=sheetName\n",
    "            )\n",
    "\n",
    "            logRows.append({\n",
    "                \"ingestRunId\": ingestRunId,\n",
    "                \"gateRunId\": gateRunId,\n",
    "                \"studyId\": studyId,\n",
    "                \"contractName\": contractName,\n",
    "                \"sequence\": sequence,\n",
    "                \"workbookFile\": workbookFile,\n",
    "                \"workbookPath\": workbookPath,\n",
    "                \"sourceSheet\": sheetName,\n",
    "                \"targetTable\": targetTable,\n",
    "                \"status\": \"SUCCESS\",\n",
    "                \"rowCount\": int(rowCount),\n",
    "                \"errorMessage\": None,\n",
    "                \"ingestTsUtc\": datetime.now(timezone.utc).isoformat()\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            logRows.append({\n",
    "                \"ingestRunId\": ingestRunId,\n",
    "                \"gateRunId\": gateRunId,\n",
    "                \"studyId\": studyId,\n",
    "                \"contractName\": contractName,\n",
    "                \"sequence\": sequence,\n",
    "                \"workbookFile\": workbookFile,\n",
    "                \"workbookPath\": workbookPath,\n",
    "                \"sourceSheet\": sheetName,\n",
    "                \"targetTable\": bronzeTableNameForSheet(sheetName),\n",
    "                \"status\": \"FAILED\",\n",
    "                \"rowCount\": None,\n",
    "                \"errorMessage\": str(e),\n",
    "                \"ingestTsUtc\": datetime.now(timezone.utc).isoformat()\n",
    "            })\n",
    "\n",
    "logPdf = pd.DataFrame(logRows)\n",
    "logSdf = spark.createDataFrame(logPdf)\n",
    "\n",
    "# Force stable types (prevents Delta merge conflicts)\n",
    "logSdf = spark.createDataFrame(pd.DataFrame(logRows))\n",
    "\n",
    "(\n",
    "    logSdf.write\n",
    "         .mode(\"append\")\n",
    "         .option(\"mergeSchema\", \"true\")\n",
    "         .saveAsTable(bronzeIngestLogTable)\n",
    ")\n",
    "\n",
    "display(logSdf.orderBy(F.col(\"status\").desc(), F.col(\"sourceSheet\")))\n",
    "print(\"Bronze ingest complete. ingestRunId:\", ingestRunId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d563c7f-1d91-4fe5-8fe9-f276898db7f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Cell 5 — Quick verification (show what got ingested this run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bd0ab43-0812-4ff8-acaa-92dd98b68e1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# Purpose:\n",
    "#   - Show ingest log rows for this run\n",
    "#   - Preview captured units (ops table)\n",
    "#   - Preview one Bronze table (data rows only)\n",
    "# Notes:\n",
    "#   - The Catalog UI \"Sample Data\" is only a preview; use SQL for full results\n",
    "# ---------------------------------------------\n",
    "\n",
    "# Make sure this matches what you set in Cell 3\n",
    "try:\n",
    "    opsSheetUnitsTable = f\"{cornellCatalog}.{cornellSchema}.opsSheetUnits\"\n",
    "except NameError:\n",
    "    opsSheetUnitsTable = \"cornell_catalog.cornell_schema.opsSheetUnits\"\n",
    "\n",
    "previewSheet = \"Milk\"  # change to \"BodyWeight\", etc. if you want\n",
    "\n",
    "# 1) Ingest log rows for this run\n",
    "display(\n",
    "    spark.sql(f\"\"\"\n",
    "        SELECT ingestRunId, gateRunId, studyId, contractName, sequence,\n",
    "               workbookFile, workbookPath, sourceSheet, targetTable,\n",
    "               status, rowCount, ingestTsUtc\n",
    "        FROM {bronzeIngestLogTable}\n",
    "        WHERE ingestRunId = '{ingestRunId}'\n",
    "        ORDER BY status DESC, sourceSheet\n",
    "    \"\"\")\n",
    ")\n",
    "\n",
    "# 2) Units captured for this run (for the chosen sheet)\n",
    "display(\n",
    "    spark.sql(f\"\"\"\n",
    "        SELECT studyId, contractName, sequence, workbookFile, sourceSheet,\n",
    "               columnName, unit, ingestRunId, ingestTsUtc\n",
    "        FROM {opsSheetUnitsTable}\n",
    "        WHERE ingestRunId = '{ingestRunId}'\n",
    "          AND sourceSheet = '{previewSheet}'\n",
    "        ORDER BY studyId, sequence, columnName\n",
    "    \"\"\")\n",
    ")\n",
    "\n",
    "# 3) Preview one bronze table (data rows only)\n",
    "display(\n",
    "    spark.sql(f\"\"\"\n",
    "        SELECT *\n",
    "        FROM {bronzeTableNameForSheet(previewSheet)}\n",
    "        WHERE ingestRunId = '{ingestRunId}'\n",
    "        ORDER BY studyId, sequence\n",
    "    \"\"\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3082acdd-5565-40ef-9cf1-cae82ca7ff84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Display delta table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ed141d5-f1ca-464b-aa2f-46076ddf137f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT *\n",
    "FROM cornell_catalog.cornell_schema.bronzeintakeperday\n",
    "ORDER BY studyId, sequence, AnimalIdentifier, Date;\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6675049096004400,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "02BronzeIngest",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}